# Techinaire_LLM_RAG_ChromaDB
Short code for setting up an LLM associated with Retrieval-Augmented Generation

# RAG with ChromaDB and Ollama

This repository contains a Jupyter Notebook showcasing how to implement a Retrieval-Augmented Generation (RAG) pipeline using **ChromaDB** as the document retriever and **Ollama** for Large Language Model (LLM) queries.

## Notebook Overview

- **Title:** RAG with ChromaDB and Ollama
- **Kernel:** ml (python3)
- **Description:** This notebook demonstrates the integration of ChromaDB and Ollama to build a scalable RAG pipeline.

## Requirements

To run this notebook, you need the following:

- Python 3.x
- Jupyter Notebook
- Required Python libraries (specified in the notebook or `requirements.txt`)

## How to Use

1. Clone this repository:
   ```bash
   git clone https://github.com/yourusername/repository-name.git
   ```
2. Navigate to the directory:
   ```bash
   cd repository-name
   ```
3. Install the dependencies:
   ```bash
   pip install -r requirements.txt
   ```
4. Launch Jupyter Notebook:
   ```bash
   jupyter notebook
   ```
5. Open the `RAG_ChromaDB_Ollama_EN.ipynb` file and run the cells sequentially.

## Features

- **Document Retrieval:** Uses ChromaDB for efficient document storage and retrieval.
- **LLM Integration:** Queries processed via Ollama framework.
- **Scalability:** Designed for handling large-scale text data.

## License

This project is licensed under the [GNU General Public License v3.0](LICENSE). You are free to use, modify, and distribute this software under the terms of the GPL.

## Acknowledgements

- [ChromaDB](https://www.trychroma.com/)
- [Ollama Framework](https://ollama.ai/)
